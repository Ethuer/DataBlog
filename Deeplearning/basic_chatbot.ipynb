{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/tensorlayer/seq2seq-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import os\n",
    "import nltk\n",
    "import gzip\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorlayer.cost import cross_entropy_seq, cross_entropy_seq_with_mask\n",
    "from tensorlayer.models.seq2seq import Seq2seq\n",
    "from tensorlayer.models.seq2seq_with_attention import Seq2seqLuongAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethuer/anaconda3/envs/tf2/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jmcauley.ucsd.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "\n",
    "url = 'https://jmcauley.ucsd.edu/data/amazon/qa/qa_Electronics.json.gz'\n",
    "\n",
    "r = requests.get(url,verify=False)\n",
    "\n",
    "with open('qa_Electronics.json.gz','wb') as localfile:\n",
    "    localfile.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the data is not in proper JSON format, so iterate over rows to get the dictionaries with ast\n",
    "data_dict = {}\n",
    "with gzip.open('qa_Electronics.json.gz','rb') as jsonfile:\n",
    "    for count, row in enumerate(jsonfile):\n",
    "        \n",
    "        row  = row.decode(\"utf-8\") \n",
    "        data_dict[count] = ast.literal_eval(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "data = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "vocabulary_size = 10000\n",
    "\n",
    "# test train split\n",
    "data = shuffle(data)\n",
    "test_train_split = 0.9\n",
    "\n",
    "train = data[:int(data.shape[0]*test_train_split)]\n",
    "test = data[int(data.shape[0]*test_train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ' '.join(train.question.tolist() + train.answer.tolist() )\n",
    "word_dict = Counter(nltk.word_tokenize(sentences) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame.from_dict({\"frequency\":word_dict}, orient='columns')\n",
    "word_df = word_df.sort_values('frequency', ascending=False)[:vocabulary_size]\n",
    "\n",
    "# add ranking\n",
    "word_df['rank'] = word_df.reset_index().index +4\n",
    "\n",
    "# add word column\n",
    "word_df['word'] = word_df.index\n",
    "\n",
    "# create mapping dictionary\n",
    "idx2word = word_df.set_index('rank')['word'].to_dict()\n",
    "word2idx = word_df.set_index('word')['rank'].to_dict()\n",
    "\n",
    "pad_id = 0\n",
    "unk_id = 1\n",
    "start_id = 2\n",
    "end_id = 3\n",
    "\n",
    "word2idx['<pad>'] = pad_id\n",
    "idx2word[pad_id] = '<pad>'\n",
    "\n",
    "word2idx['<unk>'] = unk_id\n",
    "idx2word[unk_id] = '<unk>'\n",
    "\n",
    "word2idx['<start>'] = start_id\n",
    "idx2word[start_id] = '<start>'\n",
    "\n",
    "word2idx['<end>'] = end_id\n",
    "idx2word[end_id] = '<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentence2idx(sentence):\n",
    "    \"\"\"\n",
    "    create integer list from sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    outsentence = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if word in word2idx:\n",
    "            outsentence.append(word2idx[word])\n",
    "        else:\n",
    "            outsentence.append(word2idx['<unk>'])\n",
    "    \n",
    "    return outsentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX = [sentence2idx(sent) for sent in train.question.tolist() ]\n",
    "trainY = [sentence2idx(sent) for sent in train.answer.tolist() ]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "n_step = len(trainX) // batch_size\n",
    "src_vocab_size = len(word2idx)\n",
    "emb_dim = 300\n",
    "\n",
    "#word2idx = metadata['w2idx']   # dict  word 2 index\n",
    "#idx2word = metadata['idx2w']   # list index 2 word\n",
    "\n",
    "\n",
    "src_vocab_size = tgt_vocab_size = len(word2idx) + 2\n",
    "\n",
    "num_epochs = 2\n",
    "vocabulary_size = src_vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "def inference(seed, top_n):\n",
    "        model_.eval()\n",
    "        seed_id = [word2idx.get(w, unk_id) for w in seed.split(\" \")]\n",
    "        sentence_int = model_(inputs=[[seed_id]], seq_length=20, start_token=start_id, top_n = top_n)\n",
    "        sentence_int = sentence_int.numpy().tolist()[0]\n",
    "        \n",
    "        sentence = []\n",
    "        for w_int in sentence_int:\n",
    "            if w_int == end_id:\n",
    "                break\n",
    "            word = idx2word[w_int]\n",
    "            sentence = sentence + [word]\n",
    "        return sentence\n",
    "\n",
    "decoder_seq_length = 40\n",
    "model_ = Seq2seq(\n",
    "        decoder_seq_length = decoder_seq_length,\n",
    "        cell_enc=tf.keras.layers.GRUCell,\n",
    "        cell_dec=tf.keras.layers.GRUCell,\n",
    "        n_layer=3,\n",
    "        n_units=300,\n",
    "        embedding_layer=tl.layers.Embedding(vocabulary_size=vocabulary_size, embedding_size=emb_dim),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = test.sample(3).question.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        model_.train()\n",
    "        \n",
    "        # shuffle trainingsdata\n",
    "        trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
    "        \n",
    "        # reset loss\n",
    "        total_loss, n_iter = 0, 0\n",
    "        for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False), \n",
    "                        total=n_step, desc='Epoch[{}/{}]'.format(epoch + 1, num_epochs), leave=False):\n",
    "\n",
    "            X = tl.prepro.pad_sequences(X)\n",
    "            _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
    "            _target_seqs = tl.prepro.pad_sequences(_target_seqs, maxlen=decoder_seq_length)\n",
    "            _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
    "            _decode_seqs = tl.prepro.pad_sequences(_decode_seqs, maxlen=decoder_seq_length)\n",
    "            _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                ## compute outputs\n",
    "                output = model_(inputs = [X, _decode_seqs])\n",
    "                \n",
    "                output = tf.reshape(output, [-1, vocabulary_size])\n",
    "                \n",
    "                ## compute loss and update model\n",
    "                loss = cross_entropy_seq_with_mask(logits=output, target_seqs=_target_seqs, input_mask=_target_mask)\n",
    "\n",
    "                grad = tape.gradient(loss, model_.all_weights)\n",
    "                optimizer.apply_gradients(zip(grad, model_.all_weights))\n",
    "            \n",
    "            total_loss += loss\n",
    "            n_iter += 1\n",
    "            \n",
    "            if n_iter % 2500 == 0:\n",
    "                print(f\"Saved model after {n_iter} iterations or {time.time()- start} seconds\")\n",
    "                tl.files.save_npz(model_.all_weights, name=f'model_{n_iter}.npz')\n",
    "                \n",
    "\n",
    "        # printing average loss after every epoch\n",
    "        print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, num_epochs, total_loss / n_iter))\n",
    "\n",
    "        for seed in seeds:\n",
    "            print(\"Query >\", seed)\n",
    "            top_n = 3\n",
    "            for i in range(top_n):\n",
    "                sentence = inference(seed, top_n)\n",
    "                print(\" >\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question  : DOES IT WORK WITH VISTA HOME EDITION\n",
      "Answer 1 : Yes , it is compatible with it , and I have a <unk> . I have n't used it for\n",
      "Answer 2 : Yes <end> . It 's a very <unk> . <end> for the <unk> and the other <unk> <unk> . <end>\n",
      "Answer 3 : Yes , it will not work with a <unk> . <end> <end> <unk> <unk> and <unk> <unk> <unk> . <end>\n",
      "Question  : Will this cord work on Samsung HDTV model LNS2651DX/XAA?\n",
      "Answer 1 : Yes , I do not have any problem . It will be very well for a <unk> . <end> .\n",
      "Answer 2 : Yes , I do not think the camera is compatible . <end> <end> is not the <unk> . I think\n",
      "Answer 3 : Yes it does <end> with the <unk> . I use the <unk> and it is a <unk> and I am\n",
      "Question  : Does this work with Pioneer Inno?\n",
      "Answer 1 : Yes it is a <unk> <unk> . I have a very very good <unk> . It works great for me\n",
      "Answer 2 : Yes it will <end> . It is very well with a USB drive . <end> is the <unk> and <unk>\n",
      "Answer 3 : Yes , I have the exact <unk> <unk> <end> <end> . It is very easy with the same . It\n"
     ]
    }
   ],
   "source": [
    "# 30 minute Training\n",
    "for seed in seeds:\n",
    "            print(\"Question  :\", seed)\n",
    "            top_n = 3\n",
    "            for i in range(top_n):\n",
    "                sentence = inference(seed, top_n)\n",
    "                print(f\"Answer {i+1} :\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qustion ':' Does this remote also replace NB677\n",
      "Answer 1 : <unk> . Good <unk> ! ! ! ! <unk> . Thanks ! <unk>\n",
      "Answer 2 : <unk> .\n",
      "Answer 3 : <unk> , it will work\n",
      "Qustion ':' does it convert to metric measurement\n",
      "Answer 1 : <unk> .\n",
      "Answer 2 : <unk> , <unk> ,\n",
      "Answer 3 : <unk> , <unk> ,\n",
      "Qustion ':' What comes with the camera, buying it here?\n",
      "Answer 1 : <unk> <unk>\n",
      "Answer 2 : <unk> <unk>\n",
      "Answer 3 : <unk> <unk> . <unk>\n"
     ]
    }
   ],
   "source": [
    "# ~ 1 hour Training\n",
    "for seed in seeds:\n",
    "            print(\"Question :\", seed)\n",
    "            top_n = 3\n",
    "            for i in range(top_n):\n",
    "                sentence = inference(seed, top_n)\n",
    "                print(f\"Answer {i+1} :\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
