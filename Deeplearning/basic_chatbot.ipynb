{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://github.com/tensorlayer/seq2seq-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import os\n",
    "import nltk\n",
    "import gzip\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tensorlayer.cost import cross_entropy_seq, cross_entropy_seq_with_mask\n",
    "from tensorlayer.models.seq2seq import Seq2seq\n",
    "from tensorlayer.models.seq2seq_with_attention import Seq2seqLuongAttention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ethuer/anaconda3/envs/tf2/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jmcauley.ucsd.edu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "\n",
    "url = 'https://jmcauley.ucsd.edu/data/amazon/qa/qa_Electronics.json.gz'\n",
    "\n",
    "r = requests.get(url,verify=False)\n",
    "\n",
    "with open('qa_Electronics.json.gz','wb') as localfile:\n",
    "    localfile.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the data is not in proper JSON format, so iterate over rows to get the dictionaries with ast\n",
    "data_dict = {}\n",
    "with gzip.open('qa_Electronics.json.gz','rb') as jsonfile:\n",
    "    for count, row in enumerate(jsonfile):\n",
    "        \n",
    "        row  = row.decode(\"utf-8\") \n",
    "        data_dict[count] = ast.literal_eval(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "data = pd.DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "vocabulary_size = 10000\n",
    "\n",
    "# test train split\n",
    "data = shuffle(data)\n",
    "test_train_split = 0.9\n",
    "\n",
    "train = data[:int(data.shape[0]*test_train_split)]\n",
    "test = data[int(data.shape[0]*test_train_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ' '.join(train.question.tolist() + train.answer.tolist() )\n",
    "word_dict = Counter(nltk.word_tokenize(sentences) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame.from_dict({\"frequency\":word_dict}, orient='columns')\n",
    "word_df = word_df.sort_values('frequency', ascending=False)[:vocabulary_size]\n",
    "\n",
    "# add ranking\n",
    "word_df['rank'] = word_df.reset_index().index +4\n",
    "\n",
    "# add word column\n",
    "word_df['word'] = word_df.index\n",
    "\n",
    "# create mapping dictionary\n",
    "idx2word = word_df.set_index('rank')['word'].to_dict()\n",
    "word2idx = word_df.set_index('word')['rank'].to_dict()\n",
    "\n",
    "pad_id = 0\n",
    "unk_id = 1\n",
    "start_id = 2\n",
    "end_id = 3\n",
    "\n",
    "word2idx['<pad>'] = pad_id\n",
    "idx2word[pad_id] = '<pad>'\n",
    "\n",
    "word2idx['<unk>'] = unk_id\n",
    "idx2word[unk_id] = '<unk>'\n",
    "\n",
    "word2idx['<start>'] = start_id\n",
    "idx2word[start_id] = '<start>'\n",
    "\n",
    "word2idx['<end>'] = end_id\n",
    "idx2word[end_id] = '<end>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sentence2idx(sentence):\n",
    "    \"\"\"\n",
    "    create integer list from sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    outsentence = []\n",
    "    for word in nltk.word_tokenize(sentence):\n",
    "        if word in word2idx:\n",
    "            outsentence.append(word2idx[word])\n",
    "        else:\n",
    "            outsentence.append(word2idx['<unk>'])\n",
    "    \n",
    "    return outsentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainX = [sentence2idx(sent) for sent in train.question.tolist() ]\n",
    "trainY = [sentence2idx(sent) for sent in train.answer.tolist() ]\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "n_step = len(trainX) // batch_size\n",
    "src_vocab_size = len(word2idx)\n",
    "emb_dim = 300\n",
    "\n",
    "#word2idx = metadata['w2idx']   # dict  word 2 index\n",
    "#idx2word = metadata['idx2w']   # list index 2 word\n",
    "\n",
    "\n",
    "src_vocab_size = tgt_vocab_size = len(word2idx) + 2\n",
    "\n",
    "num_epochs = 2\n",
    "vocabulary_size = src_vocab_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] Embedding embedding_1: (10006, 300)\n",
      "[TL] RNN rnn_1: cell: GRUCell, n_units: 300\n",
      "[TL] RNN rnn_2: cell: GRUCell, n_units: 300\n",
      "[TL] RNN rnn_3: cell: GRUCell, n_units: 300\n",
      "[TL] RNN rnn_4: cell: GRUCell, n_units: 300\n",
      "[TL] RNN rnn_5: cell: GRUCell, n_units: 300\n",
      "[TL] RNN rnn_6: cell: GRUCell, n_units: 300\n",
      "[TL] Reshape reshape_1\n",
      "[TL] Dense  dense_1: 10006 No Activation\n",
      "[TL] Reshape reshape_2\n",
      "[TL] Reshape reshape_3\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "def inference(seed, top_n):\n",
    "        model_.eval()\n",
    "        seed_id = [word2idx.get(w, unk_id) for w in seed.split(\" \")]\n",
    "        sentence_int = model_(inputs=[[seed_id]], seq_length=20, start_token=start_id, top_n = top_n)\n",
    "        sentence_int = sentence_int.numpy().tolist()[0]\n",
    "        \n",
    "        sentence = []\n",
    "        for w_int in sentence_int:\n",
    "            if w_int == end_id:\n",
    "                break\n",
    "            word = idx2word[w_int]\n",
    "            sentence = sentence + [word]\n",
    "        return sentence\n",
    "\n",
    "decoder_seq_length = 40\n",
    "model_ = Seq2seq(\n",
    "        decoder_seq_length = decoder_seq_length,\n",
    "        cell_enc=tf.keras.layers.GRUCell,\n",
    "        cell_dec=tf.keras.layers.GRUCell,\n",
    "        n_layer=3,\n",
    "        n_units=300,\n",
    "        embedding_layer=tl.layers.Embedding(vocabulary_size=vocabulary_size, embedding_size=emb_dim),\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = test.sample(3).question.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Whats on the end of the cable.Is it rf coax to hdmi? your description did not explain its application',\n",
       " 'Will this work with my Samsung Galaxy S4 cell phone?',\n",
       " 'Will this fit IPAD Air?']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(iterations,top_n =3 ):\n",
    "    print(f\" At {iterations} the model answers like this\")\n",
    "    for seed in seeds:\n",
    "        print(\"Question :\", seed)\n",
    "        top_n = 3\n",
    "        for i in range(top_n):\n",
    "            sentence = inference(seed, top_n)\n",
    "            print(f\"Answer {i} :\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2]: loss 5.8948\n",
      "Epoch [1/2]: loss 5.8201\n",
      "Epoch [1/2]: loss 5.8009\n",
      "Epoch [1/2]: loss 5.8056\n",
      "Epoch [1/2]: loss 5.7810\n",
      "Epoch [1/2]: loss 5.7402\n",
      "Epoch [1/2]: loss 5.7268\n",
      "Epoch [1/2]: loss 5.7408\n",
      "Epoch [1/2]: loss 5.7475\n",
      "Epoch [1/2]: loss 5.7570\n",
      "Epoch [1/2]: loss 5.7326\n",
      "Epoch [1/2]: loss 5.7344\n",
      "Epoch [1/2]: loss 5.7276\n",
      "Epoch [1/2]: loss 5.7209\n",
      "Epoch [1/2]: loss 5.7144\n",
      "Epoch [1/2]: loss 5.7185\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-105fb7ed5528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                                input_mask=_target_mask)\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SubGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n\u001b[0;32m-> 1189\u001b[0;31m       SmartBroadcastGradientArgs(x, y, grad))\n\u001b[0m\u001b[1;32m   1190\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mskip_input_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_input_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py\u001b[0m in \u001b[0;36mSmartBroadcastGradientArgs\u001b[0;34m(x, y, grad)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       and isinstance(grad, ops.Tensor)):\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0msx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0msy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mrx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_gradient_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m   6396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6397\u001b[0m     \u001b[0mexit_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit_fns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6398\u001b[0;31m     \u001b[0mexit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# False values do not suppress exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*a)\u001b[0m\n\u001b[1;32m   6387\u001b[0m       \u001b[0mscope_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_scope_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menter_eager_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6388\u001b[0m       self._exit_fns.append(\n\u001b[0;32m-> 6389\u001b[0;31m           lambda *a: setattr(ctx, \"scope_name\", old_scope_name))\n\u001b[0m\u001b[1;32m   6390\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6391\u001b[0m       \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py\u001b[0m in \u001b[0;36mscope_name\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mscope_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mscope_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;34m\"\"\"Sets scope name for the current thread.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    # set model into train mode\n",
    "    model_.train()   \n",
    "    \n",
    "    # reset loss\n",
    "    total_loss, n_iter = 0, 0\n",
    "\n",
    "    for X, Y in tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=True):\n",
    "\n",
    "        X = tl.prepro.pad_sequences(X)\n",
    "        _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
    "        _target_seqs = tl.prepro.pad_sequences(_target_seqs, maxlen=decoder_seq_length)\n",
    "        _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
    "        _decode_seqs = tl.prepro.pad_sequences(_decode_seqs, maxlen=decoder_seq_length)\n",
    "        _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            ## compute outputs\n",
    "            output = model_(inputs = [X, _decode_seqs])\n",
    "                \n",
    "            output = tf.reshape(output, [-1, vocabulary_size])\n",
    "                \n",
    "            ## compute loss and update model\n",
    "            loss = cross_entropy_seq_with_mask(logits=output, \n",
    "                                               target_seqs=_target_seqs, \n",
    "                                               input_mask=_target_mask)\n",
    "\n",
    "            grad = tape.gradient(loss, model_.all_weights)\n",
    "            optimizer.apply_gradients(zip(grad, model_.all_weights))\n",
    "            \n",
    "        total_loss += loss\n",
    "        n_iter += 1\n",
    "            \n",
    "        if n_iter % 500 == 0:\n",
    "            answer(n_iter)\n",
    "            print(f\"Saved model after {n_iter} iterations or {time.time()- start} seconds\")\n",
    "            tl.files.save_npz(model_.all_weights, name=f'model_{n_iter}.npz')\n",
    "                \n",
    "\n",
    "        # printing average loss after every epoch\n",
    "        print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, num_epochs, total_loss / n_iter))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 minute Training\n",
    "for seed in seeds:\n",
    "            print(\"Question  :\", seed)\n",
    "            top_n = 3\n",
    "            for i in range(top_n):\n",
    "                sentence = inference(seed, top_n)\n",
    "                print(f\"Answer {i+1} :\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ 1 hour Training\n",
    "for seed in seeds:\n",
    "            print(\"Question :\", seed)\n",
    "            top_n = 3\n",
    "            for i in range(top_n):\n",
    "                sentence = inference(seed, top_n)\n",
    "                print(f\"Answer {i+1} :\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
